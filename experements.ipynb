{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-12T15:14:08.526855Z","iopub.execute_input":"2025-06-12T15:14:08.527109Z","iopub.status.idle":"2025-06-12T15:14:08.530443Z","shell.execute_reply.started":"2025-06-12T15:14:08.527093Z","shell.execute_reply":"2025-06-12T15:14:08.529780Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"validate_train_url = \"https://getfile.dokpub.com/yandex/get/https://disk.yandex.ru/d/DZW9I4MwAJrl_A\"\nvalidate_test_url = \"https://getfile.dokpub.com/yandex/get/https://disk.yandex.ru/d/8nSFbNQY92HCng\"\nvalidate_answers_train_url = 'https://getfile.dokpub.com/yandex/get/https://disk.yandex.ru/d/UsSATGKzLrhBFQ'\nvalidate_answers_test = 'https://getfile.dokpub.com/yandex/get/https://disk.yandex.ru/d/iu8jIJk1C15mww'\nhistory_train_url = 'https://getfile.dokpub.com/yandex/get/https://disk.yandex.ru/d/BkZWvVVDjfB1rw'\nusers_train_url = 'https://getfile.dokpub.com/yandex/get/https://disk.yandex.ru/d/SEz-05NG0vpkKA'\nvalidate_train = pd.read_csv(validate_train_url, sep='\\t')\nvalidate_test = pd.read_csv(validate_test_url, sep='\\t')\nvalidate_answers_train = pd.read_csv(validate_answers_train_url, sep='\\t')\nvalidate_answers_test = pd.read_csv(validate_answers_test, sep='\\t')\nhistory_train = pd.read_csv(history_train_url, sep='\\t')\nusers_train = pd.read_csv(users_train_url, sep='\\t')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T15:02:06.240860Z","iopub.execute_input":"2025-06-12T15:02:06.241539Z","iopub.status.idle":"2025-06-12T15:02:25.358419Z","shell.execute_reply.started":"2025-06-12T15:02:06.241519Z","shell.execute_reply":"2025-06-12T15:02:25.357583Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"validate_train = validate_train.drop('Unnamed: 0', axis=1)\nvalidate_test = validate_test.drop('Unnamed: 0', axis=1)\nvalidate_answers_train = validate_answers_train.drop('Unnamed: 0', axis=1)\nvalidate_answers_test = validate_answers_test.drop('Unnamed: 0', axis=1)\nhistory_train = history_train.drop('Unnamed: 0', axis=1)\nusers_train = users_train.drop('Unnamed: 0', axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T15:02:25.359311Z","iopub.execute_input":"2025-06-12T15:02:25.360127Z","iopub.status.idle":"2025-06-12T15:02:25.394564Z","shell.execute_reply.started":"2025-06-12T15:02:25.360085Z","shell.execute_reply":"2025-06-12T15:02:25.393902Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"views_for_users_by_publishers = {}\nfor user_id in users_train['user_id'].unique():\n  temp = history_train[history_train['user_id'] == user_id]\n  publishers = temp['publisher'].tolist()\n  views_for_users_by_publishers[user_id] = []\n  for i in range(22):\n    views_for_users_by_publishers[user_id].append(publishers.count(i))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T15:02:25.396081Z","iopub.execute_input":"2025-06-12T15:02:25.396282Z","iopub.status.idle":"2025-06-12T15:02:51.206783Z","shell.execute_reply.started":"2025-06-12T15:02:25.396265Z","shell.execute_reply":"2025-06-12T15:02:51.206229Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"users_statistics_by_publishers = {}\nfor user_id in list(users_train['user_id'].unique()):\n    user_history = history_train[history_train['user_id'] == user_id]\n    for i in range(1,22):\n        temp_user_history = user_history[user_history['publisher'] == i]\n        users_statistics_by_publishers[(user_id, i, 'total_views')] = temp_user_history.shape[0]\n        users_statistics_by_publishers[(user_id, i, 'views_share')] = temp_user_history.shape[0]/user_history.shape[0] if user_history.shape[0] != 0 else 0\n        users_statistics_by_publishers[(user_id, i, 'min_cpm')] = temp_user_history['cpm'].min()\n        users_statistics_by_publishers[(user_id, i, 'max_cpm')] = temp_user_history['cpm'].max()\n        users_statistics_by_publishers[(user_id, i, 'mean_cpm')] = temp_user_history['cpm'].mean()\n        users_statistics_by_publishers[(user_id, i, 'median_cpm')] = temp_user_history['cpm'].median()\n        users_statistics_by_publishers[(user_id, i, 'mean_views_per_day')] = temp_user_history.shape[0]/((temp_user_history['hour'].max()-temp_user_history['hour'].min())/24) if temp_user_history['hour'].max()-temp_user_history['hour'].min() != 0 else 0\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T15:02:51.207468Z","iopub.execute_input":"2025-06-12T15:02:51.207695Z","iopub.status.idle":"2025-06-12T15:06:09.925117Z","shell.execute_reply.started":"2025-06-12T15:02:51.207677Z","shell.execute_reply":"2025-06-12T15:06:09.924488Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def count_views_by_user(user, publishers, views_for_users_by_publishers):\n    sum = 0\n    for publisher in publishers:\n        sum += views_for_users_by_publishers[user][publisher]\n    return sum","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T15:06:09.925793Z","iopub.execute_input":"2025-06-12T15:06:09.926099Z","iopub.status.idle":"2025-06-12T15:06:09.930275Z","shell.execute_reply.started":"2025-06-12T15:06:09.926057Z","shell.execute_reply":"2025-06-12T15:06:09.929512Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def make_target_dataset(validate_train, validate_answers_train, views_for_users_by_publishers, history_train, users_train, users_statistics_by_publishers):\n    target = []\n    for index in range(validate_train.shape[0]):\n        validate_row = validate_train.iloc[index]\n        validate_answer_row = validate_answers_train.iloc[index]\n        user_ids = list(map(int, (validate_row['user_ids'].replace('(', '').replace(')', '').replace(',', ' ')).split()))\n        publisher_ids = list(map(int, (validate_row['publishers'].replace('(', '').replace(')', '').replace(',', ' ')).split()))\n        array = []\n        for user_id in user_ids:\n            array.append([user_id, count_views_by_user(user_id, publisher_ids, views_for_users_by_publishers)])\n        array.sort(key=lambda item: item[1], reverse=True)\n        users = {}\n        for i in range(len(array)):\n            users[array[i][0]] = 0\n        for i in range(int(validate_answer_row['at_least_one']*len(array))):\n            users[array[i][0]] = 1\n        for i in range(int(validate_answer_row['at_least_two']*len(array))):\n            users[array[i][0]] = 2\n        for i in range(int(validate_answer_row['at_least_three']*len(array))):\n            users[array[i][0]] = 3\n        for user_id in user_ids:\n            target.append(users[user_id])\n    return pd.DataFrame({'target': target})\n            \n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T15:06:09.930857Z","iopub.execute_input":"2025-06-12T15:06:09.931107Z","iopub.status.idle":"2025-06-12T15:06:09.947451Z","shell.execute_reply.started":"2025-06-12T15:06:09.931089Z","shell.execute_reply":"2025-06-12T15:06:09.946772Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def make_feature_dataset(validate_train, views_for_users_by_publishers, history_train, users_train, users_statistics_by_publishers):\n    users_id = []\n    cpm = []\n    number_of_views = []\n    duration = []\n    min_cpm = []\n    max_cpm = []\n    mean_cpm = []\n    median_cpm = []\n    mean_views_per_day = []\n    number_of_publisher = []\n    for index in range(validate_train.shape[0]):\n        validate_row = validate_train.iloc[index]\n        validate_answer_row = validate_answers_train.iloc[index]\n        user_ids = list(map(int, (validate_row['user_ids'].replace('(', '').replace(')', '').replace(',', ' ')).split()))\n        publisher_ids = list(map(int, (validate_row['publishers'].replace('(', '').replace(')', '').replace(',', ' ')).split()))\n        \n        for user_id in user_ids:\n            duration.append(validate_row['hour_end']-validate_row['hour_start'])\n            users_id.append(user_id)\n            cpm.append(validate_row['cpm'])\n            number_of_views.append(count_views_by_user(user_id, publisher_ids, views_for_users_by_publishers))\n            number_of_publisher.append(len(publisher_ids))\n            temp_min = []\n            temp_max = []\n            temp_mean = []\n            temp_median = []\n            temp_mean_views = []\n            for publisher_id in list(map(int, (validate_row['publishers'].replace('(', '').replace(')', '').replace(',', ' ')).split())):\n                temp_min.append(users_statistics_by_publishers[(user_id, publisher_id, 'min_cpm')])\n                temp_max.append(users_statistics_by_publishers[(user_id, publisher_id, 'max_cpm')])\n                temp_mean.append(users_statistics_by_publishers[(user_id, publisher_id, 'mean_cpm')])\n                temp_median.append(users_statistics_by_publishers[(user_id, publisher_id, 'median_cpm')])\n                temp_mean_views.append(users_statistics_by_publishers[(user_id, publisher_id, 'mean_views_per_day')])\n            min_cpm.append(min(temp_min))\n            max_cpm.append(max(temp_max))\n            temp_median.sort()                                  \n            middle = temp_median[len(temp_median) // 2]        \n            median_cpm.append(middle)\n            mean_cpm.append(sum(temp_mean)/len(temp_mean))\n            mean_views_per_day.append(sum(temp_mean_views)/len(temp_mean_views))\n    return pd.DataFrame({\n        \"user_id\": users_id,\n        \"cpm\": cpm,\n        'number_of_views': number_of_views,\n        'min_cpm_per_publishers': min_cpm,\n        'max_cpm_per_publishers': max_cpm,\n        'mean_cpm_per_publishers': mean_cpm,\n        'median_cpm_per_publishers': median_cpm,\n        'mean_views_per_day': mean_views_per_day,\n        'durations': duration,\n        'number_of_publisher': number_of_publisher\n    })","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T15:06:09.948103Z","iopub.execute_input":"2025-06-12T15:06:09.948262Z","iopub.status.idle":"2025-06-12T15:06:09.962082Z","shell.execute_reply.started":"2025-06-12T15:06:09.948248Z","shell.execute_reply":"2025-06-12T15:06:09.961436Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"import random\nfrom sklearn.model_selection import train_test_split\n\nrandom.seed(42)\n\ndef preparing_data(validate_train, validate_answers_train, views_for_users_by_publishers, history_train, users_train, users_statistics_by_publishers):\n    y = make_target_dataset(validate_train, validate_answers_train, views_for_users_by_publishers, history_train, users_train, users_statistics_by_publishers)\n    X = make_feature_dataset(validate_train, views_for_users_by_publishers, history_train, users_train, users_statistics_by_publishers)\n    data = pd.concat([X, y], axis=1)\n    data = data.reindex(random.shuffle([i for i in range(data.shape[0])])).reset_index(drop=True)\n    data.fillna(0, inplace=True)\n    X_train, X_test, y_train, y_test = train_test_split(data.drop(columns=['target']), data['target'], test_size=0.3, random_state=42)\n    return X_train, X_test, y_train, y_test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T15:06:09.962646Z","iopub.execute_input":"2025-06-12T15:06:09.962802Z","iopub.status.idle":"2025-06-12T15:06:10.656930Z","shell.execute_reply.started":"2025-06-12T15:06:09.962789Z","shell.execute_reply":"2025-06-12T15:06:10.656403Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = preparing_data(validate_train, validate_answers_train, views_for_users_by_publishers, history_train, users_train, users_statistics_by_publishers)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T15:06:10.658649Z","iopub.execute_input":"2025-06-12T15:06:10.659316Z","iopub.status.idle":"2025-06-12T15:06:14.340306Z","shell.execute_reply.started":"2025-06-12T15:06:10.659298Z","shell.execute_reply":"2025-06-12T15:06:14.339426Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV, train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import classification_report\nfrom xgboost import XGBClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.svm import SVC","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T15:06:14.341187Z","iopub.execute_input":"2025-06-12T15:06:14.341426Z","iopub.status.idle":"2025-06-12T15:06:14.996145Z","shell.execute_reply.started":"2025-06-12T15:06:14.341400Z","shell.execute_reply":"2025-06-12T15:06:14.995597Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"pipelines = {\n    'logreg': Pipeline([\n        ('scaler', StandardScaler()),\n        ('clf', LogisticRegression(multi_class='multinomial', solver='saga', max_iter=5000))\n    ]),\n    'rf': Pipeline([\n        ('clf', RandomForestClassifier(random_state=42))\n    ]),\n    'xgb_gpu': Pipeline([\n        ('clf', XGBClassifier(\n            objective='multi:softprob',\n            num_class=4,\n            use_label_encoder=False,\n            eval_metric='mlogloss',\n            device='cuda',        \n            tree_method='hist',   \n            random_state=42\n        ))\n    ])\n}\n\nparam_grids = {\n    'logreg': {\n        'clf__C': [0.01, 0.1, 1, 10],\n        'clf__penalty': ['l2']\n    },\n    'rf': {\n        'clf__n_estimators': [100, 200],\n        'clf__max_depth': [None, 10, 20],\n        'clf__min_samples_split': [2, 5]\n    },\n    'xgb_gpu': {\n        'clf__n_estimators': [100, 200],\n        'clf__max_depth': [3, 5],\n        'clf__learning_rate': [0.01, 0.1],\n    }\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T15:18:38.197389Z","iopub.execute_input":"2025-06-12T15:18:38.198173Z","iopub.status.idle":"2025-06-12T15:18:38.205384Z","shell.execute_reply.started":"2025-06-12T15:18:38.198144Z","shell.execute_reply":"2025-06-12T15:18:38.204518Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"best_estimators = {}\n\nfor name in pipelines:\n    print(f\"\\n===== GridSearch for {name} =====\")\n    grid = GridSearchCV(\n        estimator=pipelines[name],\n        param_grid=param_grids[name],\n        scoring='accuracy',      # можно 'f1_macro', 'roc_auc_ovr' и т.д.\n        cv=5,\n        n_jobs=-1,\n        verbose=1\n    )\n    grid.fit(X_train, y_train)\n    print(f\"Best params for {name}: {grid.best_params_}\")\n    print(f\"Best CV score: {grid.best_score_:.4f}\")\n\n    best_estimators[name] = grid.best_estimator_\n\nfor name, est in best_estimators.items():\n    y_pred = est.predict(X_test)\n    print(f\"\\n*** Report for {name} ***\")\n    print(classification_report(y_test, y_pred, digits=4))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T15:18:45.416135Z","iopub.execute_input":"2025-06-12T15:18:45.416623Z","iopub.status.idle":"2025-06-12T15:26:38.488955Z","shell.execute_reply.started":"2025-06-12T15:18:45.416603Z","shell.execute_reply":"2025-06-12T15:26:38.488284Z"}},"outputs":[{"name":"stdout","text":"\n===== GridSearch for logreg =====\nFitting 5 folds for each of 4 candidates, totalling 20 fits\nBest params for logreg: {'clf__C': 0.01, 'clf__penalty': 'l2'}\nBest CV score: 0.9433\n\n===== GridSearch for rf =====\nFitting 5 folds for each of 12 candidates, totalling 60 fits\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Best params for rf: {'clf__max_depth': None, 'clf__min_samples_split': 2, 'clf__n_estimators': 200}\nBest CV score: 0.9951\n\n===== GridSearch for xgb_gpu =====\nFitting 5 folds for each of 8 candidates, totalling 40 fits\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [15:25:40] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\nPotential solutions:\n- Use a data structure that matches the device ordinal in the booster.\n- Set the device for booster before call to inplace_predict.\n\nThis warning will only be shown once.\n\n  warnings.warn(smsg, UserWarning)\n/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [15:25:40] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\nPotential solutions:\n- Use a data structure that matches the device ordinal in the booster.\n- Set the device for booster before call to inplace_predict.\n\nThis warning will only be shown once.\n\n  warnings.warn(smsg, UserWarning)\n","output_type":"stream"},{"name":"stdout","text":"Best params for xgb_gpu: {'clf__learning_rate': 0.1, 'clf__max_depth': 5, 'clf__n_estimators': 200}\nBest CV score: 0.9954\n\n*** Report for logreg ***\n              precision    recall  f1-score   support\n\n           0     0.9699    0.9924    0.9810     45838\n           1     0.3630    0.3072    0.3327      1846\n           2     0.5000    0.0014    0.0028       716\n           3     0.7878    0.7357    0.7609       999\n\n    accuracy                         0.9472     49399\n   macro avg     0.6552    0.5092    0.5193     49399\nweighted avg     0.9367    0.9472    0.9381     49399\n\n\n*** Report for rf ***\n              precision    recall  f1-score   support\n\n           0     0.9981    0.9992    0.9987     45838\n           1     0.9616    0.9496    0.9556      1846\n           2     0.9638    0.9302    0.9467       716\n           3     0.9840    0.9840    0.9840       999\n\n    accuracy                         0.9960     49399\n   macro avg     0.9769    0.9657    0.9712     49399\nweighted avg     0.9960    0.9960    0.9960     49399\n\n\n*** Report for xgb_gpu ***\n              precision    recall  f1-score   support\n\n           0     0.9988    0.9990    0.9989     45838\n           1     0.9592    0.9556    0.9574      1846\n           2     0.9313    0.9274    0.9293       716\n           3     0.9789    0.9770    0.9780       999\n\n    accuracy                         0.9959     49399\n   macro avg     0.9671    0.9647    0.9659     49399\nweighted avg     0.9959    0.9959    0.9959     49399\n\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"def predict(model, validate_test):\n    at_least_one = []\n    at_least_two = []\n    at_least_three = []\n    for index in range(validate_test.shape[0]):\n        row = validate_test.iloc[index]\n        X_test = make_feature_dataset(pd.DataFrame([row]) , views_for_users_by_publishers, history_train, users_train, users_statistics_by_publishers)\n        pred = model.predict(X_test)\n        at_least_one.append(list(pred).count(1)/len(pred))\n        at_least_two.append(list(pred).count(2)/len(pred))\n        at_least_three.append(list(pred).count(3)/len(pred))\n    return pd.DataFrame({\n        \"at_least_one\": at_least_one,\n        \"at_least_two\": at_least_two,\n        'at_least_three': at_least_three\n    })","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T16:08:46.905677Z","iopub.execute_input":"2025-06-12T16:08:46.905980Z","iopub.status.idle":"2025-06-12T16:08:46.911379Z","shell.execute_reply.started":"2025-06-12T16:08:46.905931Z","shell.execute_reply":"2025-06-12T16:08:46.910757Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"def load_answers(answers_filename):\n    return pd.read_csv(answers_filename, sep=\"\\t\")\n\n\ndef get_smoothed_log_mape_column_value(responses_column, answers_column, epsilon):\n    return np.abs(np.log(\n        (responses_column + epsilon)\n        / (answers_column + epsilon)\n    )).mean()\n\n\ndef get_smoothed_mean_log_accuracy_ratio(answers, responses, epsilon=0.005):\n    log_accuracy_ratio_mean = np.array(\n        [\n            get_smoothed_log_mape_column_value(responses.at_least_one, answers.at_least_one, epsilon),\n            get_smoothed_log_mape_column_value(responses.at_least_two, answers.at_least_two, epsilon),\n            get_smoothed_log_mape_column_value(responses.at_least_three, answers.at_least_three, epsilon),\n        ]\n    ).mean()\n\n    percentage_error = 100 * (np.exp(log_accuracy_ratio_mean) - 1)\n\n    return percentage_error.round(\n        decimals=2\n    )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T16:05:14.474304Z","iopub.execute_input":"2025-06-12T16:05:14.474562Z","iopub.status.idle":"2025-06-12T16:05:14.480044Z","shell.execute_reply.started":"2025-06-12T16:05:14.474544Z","shell.execute_reply":"2025-06-12T16:05:14.479364Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"pred = predict(best_estimators['xgb_gpu'], validate_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T16:12:42.592047Z","iopub.execute_input":"2025-06-12T16:12:42.592280Z","iopub.status.idle":"2025-06-12T16:12:48.486531Z","shell.execute_reply.started":"2025-06-12T16:12:42.592265Z","shell.execute_reply":"2025-06-12T16:12:48.485986Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"percentage_error_test = get_smoothed_mean_log_accuracy_ratio(validate_answers_test, pred)\nprint(f'Percentage Error on Test: {percentage_error_test}%')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T16:12:53.023264Z","iopub.execute_input":"2025-06-12T16:12:53.023861Z","iopub.status.idle":"2025-06-12T16:12:53.031152Z","shell.execute_reply.started":"2025-06-12T16:12:53.023840Z","shell.execute_reply":"2025-06-12T16:12:53.030483Z"}},"outputs":[{"name":"stdout","text":"Percentage Error on Test: 285.82%\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n/usr/local/lib/python3.11/dist-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n/usr/local/lib/python3.11/dist-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n","output_type":"stream"}],"execution_count":39}]}