# Метрика

Задача оценивается по метрике, которая считается значениям из всех трех колонок –`at_least_one`, `at_least_two` и `at_least_three`.

Метрика – Smoothed Mean Log Accuracy Ratio, переведенная в проценты.

$$ 100\% \cdot \left( \exp \left( \frac{1}{n} \sum_{i=1}^{n}\left|\log\left(\frac{ Predicted_i + \epsilon}{Actual_i + \epsilon}\right)\right| \right) - 1 \right) $$

$\epsilon = 0.005$

![](images/metric.png)

EPS = 0.005

Метрика интерпретируется следующим образом: это среднее значение относительного расхождения эталона и предсказанного значения в процентах. 

Например, значение 30% значит, что в среднем модель ошибается на 30% от реальности. Чем ближе метрика к 0 – тем лучше.

Сглаживание в метрике нужно, чтобы уменьшить влияние относительной ошибки там, где эталон близок к нулю. 

Логарифм в метрике берется для того, чтобы overpredict и underpredict расчитывались симметрично.


# Baseline

За baseline моделей мы выбрали обычную линейную регрессию на наборе данных из validate (Linear Regression). Это простая модель, которую удобно легко и быстро сравнивать с другими линейными моделями.

# Первые эксперименты с моделями

Чтобы чуть-чуть улучшить baseline попробовали добавить новые признаки. Исследуя аудиторию, на которую рассчитано объявление добавили средний возраст аудитории, процент людей
в возрасте от 6 до 15, от 16 до 25, от 26 до 60, от 61 до 75, процент мужчин, процент людей из самых популярных городов.

Изучая платформы добавили признаки: средний/min/max cpm на платформе, топ-5 самых активных часов на платформе.

Добавление новых признаков несколько улучшило результат в сравнении с baseline, хотя и появилось некоторое переобучение. Исследовали наиболее важные признаки.

Ridge регуляризация практически никак не меняет результат, ElasticNet-model дает похожие результаты, но в итоге мы избавились от переобучения.

Отдельно смотрели на те же эксперименты с доп. признаками: средняя медиана cpm для пользователей из выбранной аудитории утром, днём и вечером. Аналогично предпосчитали общее количество просмотров.

(В таблице представлены лучшие результаты).

Попробовали зайти с другой стороны. Завели функцию которая для каждого набора пользователей предподсчитывает среднее и суммарное количество показов для пользователей, используя таблицу history.

Обучили линейную регрессию, но предсказывали однако суммарное количество показов для каждой аудитории. Результат оказался хуже baseline.

Добавили аналогичные признаки для cpm. И для прогнозирования теперь использовали Light Gradient Boosted. Однако это не помогло улучшить показатели метрики.

Затем добавили в признаки количество уникальных сессий (за основу брали временные разрывы в 6+ часов), площадки (publishers) стали рассматривать как категориальный признак и закодировали (one-hot encoding), обучили LightGBM, но результат оказался хуже baseline.


| Модель | (Гипер параметры) | SMLAR (train)| SMLAR (test)|
| --- | --- | --- | --- |
| baseline (LR) | - | 231.64% | 239.14% |
| LinearRegression (+ признаки) | - | 189.75% | 213.18% |
| Lasso | 'alpha': 0.1 | 189.57% | 212.28% |
| Ridge | 'alpha': 0.1 | 361.4% | 367.02% |
| ElasticNet | 'alpha': 0.1, 'l1_ratio': 0.1 | 202.11% | 214.1% |
| LinearRegression (2ой подход) | - | - | 229.37% |
| Light Gradient Boosted (2ой подход) | - | - | 229.49% |


# Более сложные модели

Добавляем более сложные модели: Decision Tree и Random Forest. Перебираем гиперпараметры по сетке grid-search.

Получили неплохие результаты, значительно улучшили baseline, но Random Forest несколько переобучен. Попробовали посмотреть на зависимость Train и Test метрик от гиперпараметров и выбрали оптимальные.

K-Nearest Neighbors после обработки дает результат значительно лучший, чем baseline, однако результат не превзошел Decision Tree и Random Forest.

Наконец попробовали использовать и GradientBoostingRegressor и XGBRegressor, но у модели такое сильное переобучение, которое не получилось устранить ничем.

| Модель | (Гипер параметры) | SMLAR (train)| SMLAR (test)|
| --- | --- | --- | --- |
| DecisionTreeRegressor | 'max_depth': 5 | 57.94% | 75.79% |
| RandomForestRegressor | 'max_depth': 10, 'n_estimators': 50 | 28.81% | 55.52% |
| K-Nearest Neighbors |  'n_neighbors': 3 | 91.82% | 159.54% |
| GradientBoostingRegressor | - | 1.61% | 53.1% |
| XGBRegressor | - | 4.99% | 204.24% |

# Обучение с предподсчетами
Далее мы попробовали обучить модель, которая будет предсказывать сколько раз увидел рекламное объявление каждый отдельный user из validate['user_ids'].
Для этого на основе имеющихся датасетов мы собрали новый. Каждую строку validate мы превращаем в новый набор строк: все возможные комбинации user_id из validate['user_ids'] и publisher из validate['publishers'] дополняем информацией о пользователе из users и новыми предподсчитанными параметрами. В качестве target выступают 'one_view_probability', 'two_view_probability' и 'three_view_probability'. То как они получены разберем на примере "one_view_probability". Считаем, что для пользователя значение one_view_probability равно числу находящемуся в validate['at_least_one'], а между площадками распределяем пропорционально количеству просмотров пользователя на площадке.

После этого обучаем три разные модели предсказывать 'one_view_probability', 'two_view_probability' и 'three_view_probability'.

Для получения предсказания в формате требующемся в условие мы для каждого пользователя из validate['user_ids], на каждой площадке предсказываем 'one_view_probability', 'two_view_probability' и 'three_view_probability'. Потом cуммируем показатели для всех площадок для каждого пользователя, и берем mean этих значений по всем пользователям, соответственно получив значения 'at_least_one', 'at_least_two', 'at_least_three'.

Лучшим достижением этого подхода стал результат метрики: 113.12%. Для получения этого значения использовались три модели XGBRegressor. Каждая модель показывала результат $R 2$ на test выборке более 0.98. Это говорит о следующем, что модель описанная в построение датасета не идеальна. Мы уперлись именно в корректность гипотезы, что для каждого пользователя вероятности увидеть объявления равны 'at_least_one', 'at_least_two', 'at_least_three'.
Стоит также отметить, что лучший показатель точности для моделей, которые обучались на выборке, разделенной на test и train по правилу указанному в условии задачи: "Ваш алгоритм будет тестироваться на следующем месяце, после доступной вам истории показов. То есть, hour_start и hour_end в тестовых заданиях не будут пересекаться с hour из доступной вам  history.tsv .". Стоит отметить, что у этого подхода есть и технический минус - время затраченное на предсказание сильно увеличилось.

Эти модели были объеденины в один pipeline - MyPredictor.

Ноутбук с этим экспериментом "viktor_advanced_experements.ipynb"  лежит в ветке viktor/experiments.

Были предприняты и другие эксперименты обучить модель, которая будет предсказывать сколько раз увидел рекламное объявление каждый отдельный user.
Был построен следующий dataset: пользователи из validate['user_ids'] были отсортированы в порядке убывания общего количества просмотров на площадках из validate['publishers']. После чего был сформирован столбец 'target' по следующему правилу: пользователи, которые вошли в первые (100*validate_answers['at_least_three]) процентов по количеству просмотров получили target = 3(мы предположили, что они увидели рекламу хотя бы 3 раза); те, что вошли в (100*validate_answers['at_least_two]) процентов по количеству просмотров получили target = 2(мы предположили, что они увидели рекламу хотя бы 2 раза); те, что вошли в (100*validate_answers['at_least_one]) процентов по количеству просмотров получили target = 1(мы предположили, что они увидели рекламу хотя бы 1 раза); остальные получили target = 0.

После этого мы обучили модель предсказывать target для каждого пользователя. Для получения предсказания в формате требующемся в условие мы находим долю пользователей с соответствующим значением target.

Используя такой подход мы получили значение метрики: 285.82%. Этот результат говорит о том, что данный подход грубее предыдущего, поэтому мы не продолжили свои эксперименты с ним.

Ноутбук с этим экспериментом "experements.ipynb"  лежит в ветке viktor/experiments.
