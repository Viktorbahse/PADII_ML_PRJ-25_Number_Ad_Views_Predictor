# Метрика

Задача оценивается по метрике, которая считается значениям из всех трех колонок –`at_least_one`, `at_least_two` и `at_least_three`.

Метрика – Smoothed Mean Log Accuracy Ratio, переведенная в проценты.

$$ 100\% \cdot \left( \exp \left( \frac{1}{n} \sum_{i=1}^{n}\left|\log\left(\frac{ Predicted_i + \epsilon}{Actual_i + \epsilon}\right)\right| \right) - 1 \right) $$

$\epsilon = 0.005$

![](images/metric.png)

EPS = 0.005

Метрика интерпретируется следующим образом: это среднее значение относительного расхождения эталона и предсказанного значения в процентах. 

Например, значение 30% значит, что в среднем модель ошибается на 30% от реальности. Чем ближе метрика к 0 – тем лучше.

Сглаживание в метрике нужно, чтобы уменьшить влияние относительной ошибки там, где эталон близок к нулю. 

Логарифм в метрике берется для того, чтобы overpredict и underpredict расчитывались симметрично.


# Baseline

За baseline моделей мы выбрали обычную линейную регрессию на наборе данных из validate (Linear Regression). Это простая модель, которую удобно легко и быстро сравнивать с другими линейными моделями.

# Первые эксперименты с моделями

Чтобы чуть-чуть улучшить baseline попробовали добавить новые признаки. Исследуя аудиторию, на которую рассчитано объявление добавили средний возраст аудитории, процент людей
в возрасте от 6 до 15, от 16 до 25, от 26 до 60, от 61 до 75, процент мужчин, процент людей из самых популярных городов.

Изучая платформы добавили признаки: средний/min/max cpm на платформе, топ-5 самых активных часов на платформе.

Добавление новых признаков несколько улучшило результат в сравнении с baseline, хотя и появилось некоторое переобучение. Исследовали наиболее важные признаки.

Ridge регуляризация практически никак не меняет результат, ElasticNet-model дает похожие результаты, но в итоге мы избавились от переобучения.

Отдельно смотрели на те же эксперименты с доп. признаками: средняя медиана cpm для пользователей из выбранной аудитории утром, днём и вечером. Аналогично предпосчитали общее количество просмотров.

(В таблице представлены лучшие результаты).

Попробовали зайти с другой стороны. Завели функцию которая для каждого набора пользователей предподсчитывает среднее и суммарное количество показов для пользователей, используя таблицу history.

Обучили линейную регрессию, но предсказывали однако суммарное количество показов для каждой аудитории. Результат оказался хуже baseline.

Добавили аналогичные признаки для cpm. И для прогнозирования теперь использовали Light Gradient Boosted. Однако это не помогло улучшить показатели метрики.

Затем добавили в признаки количество уникальных сессий (за основу брали временные разрывы в 6+ часов), площадки (publishers) стали рассматривать как категориальный признак и закодировали (one-hot encoding), обучили LightGBM, но результат оказался хуже baseline.


| Модель | (Гипер параметры) | SMLAR (train)| SMLAR (test)|
| --- | --- | --- | --- |
| baseline (LR) | - | 231.64% | 239.14% |
| LinearRegression (+ признаки) | - | 189.75% | 213.18% |
| Lasso | 'alpha': 0.1 | 189.57% | 212.28% |
| Ridge | 'alpha': 0.1 | 361.4% | 367.02% |
| ElasticNet | 'alpha': 0.1, 'l1_ratio': 0.1 | 202.11% | 214.1% |
| LinearRegression (2ой подход) | - | - | 229.37% |
| Light Gradient Boosted (2ой подход) | - | - | 229.49% |


# Более сложные модели

Добавляем более сложные модели: Decision Tree и Random Forest. Перебираем гиперпараметры по сетке grid-search.

Получили неплохие результаты, значительно улучшили baseline, но Random Forest несколько переобучен. Попробовали посмотреть на зависимость Train и Test метрик от гиперпараметров и выбрали оптимальные.

K-Nearest Neighbors после обработки дает результат значительно лучший, чем baseline, однако результат не превзошел Decision Tree и Random Forest.

Наконец попробовали использовать и GradientBoostingRegressor и XGBRegressor, но у модели такое сильное переобучение, которое не получилось устранить ничем.

| Модель | (Гипер параметры) | SMLAR (train)| SMLAR (test)|
| --- | --- | --- | --- |
| DecisionTreeRegressor | 'max_depth': 5 | 57.94% | 75.79% |
| RandomForestRegressor | 'max_depth': 10, 'n_estimators': 50 | 28.81% | 55.52% |
| K-Nearest Neighbors |  'n_neighbors': 3 | 91.82% | 159.54% |
| GradientBoostingRegressor | - | 1.61% | 53.1% |
| XGBRegressor | - | 4.99% | 204.24% |

# Обучение с предподсчетами

Далее мы попробовали обучить модель, предподсчитав какую-то информацию про пользователей, используя датасет history.

Подсчитанные признаки: 'total_views', 'views_share', 'min_cpm', 'max_cpm', 'mean_cpm', 'median_cpm', 'mean_views_per_day'.

Создали датасет, чтобы предсказывать вероятность увидеть объявление для отдельного пользователя.

TODO: кратко - как?

На полученном расширенном датасете обучили PoissonRegressor, Lasso и Ridge модели, выбрали лучшую для каждого предсказания (для доли пользователей, увидевших объявление 1, 2 и 3 раза).

Резьтат оказался немного лучше чем baseline.

Используем теперь XGBRegressor, медиану, TODO: ???, ??

| Модель | SMLAR (test)|
| --- | --- | --- |
| PoissonRegressor, Lasso, Ridge | 146.88% |
| XGBRegressor | 113.12% |
| Median | 163.61% |

???

# TODO: последние эксперименты Вити

????
