{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oAD9Ju-AlxfQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validate_train_url = \"https://getfile.dokpub.com/yandex/get/https://disk.yandex.ru/d/DZW9I4MwAJrl_A\"\n",
        "validate_test_url = \"https://getfile.dokpub.com/yandex/get/https://disk.yandex.ru/d/8nSFbNQY92HCng\"\n",
        "validate_answers_train_url = 'https://getfile.dokpub.com/yandex/get/https://disk.yandex.ru/d/UsSATGKzLrhBFQ'\n",
        "validate_answers_test = 'https://getfile.dokpub.com/yandex/get/https://disk.yandex.ru/d/iu8jIJk1C15mww'\n",
        "history_train_url = 'https://getfile.dokpub.com/yandex/get/https://disk.yandex.ru/d/BkZWvVVDjfB1rw'\n",
        "users_train_url = 'https://getfile.dokpub.com/yandex/get/https://disk.yandex.ru/d/SEz-05NG0vpkKA'\n",
        "validate_train = pd.read_csv(validate_train_url, sep='\\t')\n",
        "validate_test = pd.read_csv(validate_test_url, sep='\\t')\n",
        "validate_answers_train = pd.read_csv(validate_answers_train_url, sep='\\t')\n",
        "validate_answers_test = pd.read_csv(validate_answers_test, sep='\\t')\n",
        "history_train = pd.read_csv(history_train_url, sep='\\t')\n",
        "users_train = pd.read_csv(users_train_url, sep='\\t')\n"
      ],
      "metadata": {
        "id": "AlcwQEODQ6zv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "usefull_columns = ['cpm', 'hour_start', 'hour_end', 'audience_size', 'average_age', 'percent_6_15',\n",
        "       'percent_16_25', 'percent_26_45', 'percent_46_60', 'percent_60_75',\n",
        "       'percent_70_90', 'percent_men', 'unique_cities',\n",
        "       'percent_cities_3_7_19_25', 'mean_users_mean_cpm',\n",
        "       'mean_users_median_cpm', 'mean_users_min_cpm', 'mean_total_views',\n",
        "       'unique_publishers', 'mean_users_mean_night_cpm',\n",
        "       'mean_users_median_night_cpm', 'mean_users_min_night_cpm',\n",
        "       'mean_users_total_views_night', 'mean_users_mean_morning_cpm',\n",
        "       'mean_users_median_morning_cpm', 'mean_users_min_morning_cpm',\n",
        "       'mean_users_total_views_morning', 'mean_users_mean_day_cpm',\n",
        "       'mean_users_median_day_cpm', 'mean_users_min_day_cpm',\n",
        "       'mean_users_total_views_day', 'mean_users_mean_evening_cpm',\n",
        "       'mean_users_median_evening_cpm', 'mean_users_min_evening_cpm',\n",
        "       'mean_users_total_views_evening', 'average_cpm', 'min_cpm', 'max_cpm',\n",
        "       'most_active_hour', 'second_active_hour', 'third_active_hour',\n",
        "       'fourth_active_hour', 'fifth_active_hour']"
      ],
      "metadata": {
        "id": "EDHca-NaTfcm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Tuple\n",
        "from sklearn.metrics import make_scorer\n",
        "\n",
        "def load_answers(answers_filename):\n",
        "    return pd.read_csv(answers_filename, sep=\"\\t\")\n",
        "\n",
        "\n",
        "def get_smoothed_log_mape_column_value(responses_column, answers_column, epsilon):\n",
        "    return np.abs(np.log(\n",
        "        (responses_column + epsilon)\n",
        "        / (answers_column + epsilon)\n",
        "    )).mean()\n",
        "\n",
        "\n",
        "def get_smoothed_mean_log_accuracy_ratio(answers, responses, epsilon=0.005):\n",
        "    log_accuracy_ratio_mean = np.array(\n",
        "        [\n",
        "            get_smoothed_log_mape_column_value(responses.at_least_one, answers.at_least_one, epsilon),\n",
        "            get_smoothed_log_mape_column_value(responses.at_least_two, answers.at_least_two, epsilon),\n",
        "            get_smoothed_log_mape_column_value(responses.at_least_three, answers.at_least_three, epsilon),\n",
        "        ]\n",
        "    ).mean()\n",
        "\n",
        "    percentage_error = 100 * (np.exp(log_accuracy_ratio_mean) - 1)\n",
        "\n",
        "    return percentage_error.round(\n",
        "        decimals=2\n",
        "    )\n",
        "\n",
        "def custom_scorer(y_true, y_pred):\n",
        "    responses = pd.DataFrame(y_pred, columns=['at_least_one', 'at_least_two', 'at_least_three'])\n",
        "    answers = y_true.reset_index(drop=True)\n",
        "    return get_smoothed_mean_log_accuracy_ratio(answers, responses)\n",
        "\n",
        "custom_scorer_func = make_scorer(custom_scorer, greater_is_better=False)"
      ],
      "metadata": {
        "id": "bjD4bT4iTIzi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Начнем эксперементы с 3-х одинаковых RandomForestRegressor."
      ],
      "metadata": {
        "id": "q-BfSBUhUrpJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_xy(X_data: pd.DataFrame, y_data: pd.DataFrame) -> Tuple[pd.DataFrame, pd.Series]:\n",
        "    X = X_data[usefull_columns]\n",
        "    y = y_data[['at_least_one', 'at_least_two', 'at_least_three']]\n",
        "    return X, y\n"
      ],
      "metadata": {
        "id": "sFbk7MQIWoUP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
        "\n",
        "X_train, y_train = make_xy(validate_train, validate_answers_train)\n",
        "X_test, y_test = make_xy(validate_test, validate_answers_test)\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred_train = model.predict(X_train)\n",
        "y_pred_test = model.predict(X_test)\n",
        "\n",
        "responses_train = pd.DataFrame(y_pred_train, columns=['at_least_one', 'at_least_two', 'at_least_three'])\n",
        "answers_train = y_train.reset_index(drop=True)\n",
        "responses_test = pd.DataFrame(y_pred_test, columns=['at_least_one', 'at_least_two', 'at_least_three'])\n",
        "answers_test = y_test.reset_index(drop=True)\n",
        "\n",
        "percentage_error_train = get_smoothed_mean_log_accuracy_ratio(answers_train, responses_train)\n",
        "percentage_error_test = get_smoothed_mean_log_accuracy_ratio(answers_test, responses_test)\n",
        "print(f'Percentage Error on Train: {percentage_error_train}%')\n",
        "print(f'Percentage Error on Test: {percentage_error_test}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAHcetc2V_u3",
        "outputId": "9119a273-1245-403c-cc69-979bd6629f15"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percentage Error on Train: 153.67%\n",
            "Percentage Error on Test: 192.56%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
        "custom_scorer_func = make_scorer(get_smoothed_mean_log_accuracy_ratio,\n",
        "                                greater_is_better=False)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "models = {\n",
        "    'Ridge Regression': (Ridge(), {'alpha': np.logspace(-5, 3, 30), 'max_iter': [1000, 5000, 10000]}),\n",
        "    'Lasso Regression': (Lasso(), {'alpha': np.logspace(-5, 3, 30), 'max_iter': [1000, 5000, 10000]})\n",
        "}\n",
        "\n",
        "error_res = {}\n",
        "\n",
        "for model_name, (model, params) in models.items():\n",
        "    grid_search = GridSearchCV(\n",
        "        estimator=model,\n",
        "        param_grid=params,\n",
        "        scoring=custom_scorer_func,\n",
        "        cv=5,\n",
        "        n_jobs=-1,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    grid_search.fit(X_train_scaled, y_train)\n",
        "    best_model = grid_search.best_estimator_\n",
        "\n",
        "    y_pred_train = best_model.predict(X_train_scaled)\n",
        "    y_pred_test = best_model.predict(X_test_scaled)\n",
        "    responses_train = pd.DataFrame(y_pred_train, columns=['at_least_one', 'at_least_two', 'at_least_three'])\n",
        "    answers_train = pd.DataFrame(y_train.reset_index(drop=True), columns=['at_least_one', 'at_least_two', 'at_least_three'])\n",
        "\n",
        "    responses_test = pd.DataFrame(y_pred_test, columns=['at_least_one', 'at_least_two', 'at_least_three'])\n",
        "    answers_test = pd.DataFrame(y_test.reset_index(drop=True), columns=['at_least_one', 'at_least_two', 'at_least_three'])\n",
        "\n",
        "    train_error = get_smoothed_mean_log_accuracy_ratio(answers_train, responses_train)\n",
        "    test_error = get_smoothed_mean_log_accuracy_ratio(answers_test, responses_test)\n",
        "\n",
        "    error_res[model_name] = {\n",
        "        'best_params': grid_search.best_params_,\n",
        "        'train_error': train_error,\n",
        "        'test_error': test_error,\n",
        "        'model': best_model\n",
        "    }"
      ],
      "metadata": {
        "id": "tZnNAO7CGkN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model_name, errors in error_res.items():\n",
        "    print(f\"\\n{model_name}:\")\n",
        "    print(f\"Best Parameters: {errors['best_params']}\")\n",
        "    print(f\"Train Error: {errors['train_error']:.2f}%\")\n",
        "    print(f\"Test Error: {errors['test_error']:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2yynCeGKTrr",
        "outputId": "edac367a-acdd-4b27-965d-d51cd9ea614d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Ridge Regression:\n",
            "Best Parameters: {'alpha': np.float64(1e-05), 'max_iter': 1000}\n",
            "Train Error: 153.66%\n",
            "Test Error: 192.56%\n",
            "\n",
            "Lasso Regression:\n",
            "Best Parameters: {'alpha': np.float64(1e-05), 'max_iter': 1000}\n",
            "Train Error: 150.40%\n",
            "Test Error: 190.87%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "model = GradientBoostingRegressor(\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.01,\n",
        "    max_depth=3,\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=2\n",
        ")\n",
        "y_pred_train = pd.DataFrame()\n",
        "y_pred_test = pd.DataFrame()\n",
        "\n",
        "for column in y_train.columns:\n",
        "    model.fit(X_train, y_train[column])\n",
        "    y_pred_train[column] = model.predict(X_train)\n",
        "    y_pred_test[column] = model.predict(X_test)\n",
        "\n",
        "responses_train = pd.DataFrame(y_pred_train, columns=['at_least_one', 'at_least_two', 'at_least_three'])\n",
        "answers_train = y_train.reset_index(drop=True)\n",
        "responses_test = pd.DataFrame(y_pred_test, columns=['at_least_one', 'at_least_two', 'at_least_three'])\n",
        "answers_test = y_test.reset_index(drop=True)\n",
        "\n",
        "percentage_error_train = get_smoothed_mean_log_accuracy_ratio(answers_train, responses_train)\n",
        "percentage_error_test = get_smoothed_mean_log_accuracy_ratio(answers_test, responses_test)\n",
        "print(f'Percentage Error on Train: {percentage_error_train}%')\n",
        "print(f'Percentage Error on Test: {percentage_error_test}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOZ37JfJigWN",
        "outputId": "aa5df3c3-8ef8-4593-89e2-e00eb1e6bf54"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percentage Error on Train: 184.16%\n",
            "Percentage Error on Test: 283.6%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer\n",
        "\n",
        "param_grid = [\n",
        "    {\n",
        "        'n_estimators': [50, 100, 150],\n",
        "        'learning_rate': [0.01, 0.05, 0.1],\n",
        "        'max_depth': [1, 2, 3],\n",
        "    },\n",
        "    {\n",
        "        'n_estimators': [50, 100],\n",
        "        'max_depth': [2, 3],\n",
        "        'min_samples_split': [2, 5, 10],\n",
        "        'min_samples_leaf': [1, 3, 5],\n",
        "        'subsample': [0.8, 0.9, 1.0],\n",
        "    },\n",
        "    {\n",
        "        'n_estimators': [200],\n",
        "        'learning_rate': [0.05, 0.1],\n",
        "        'max_depth': [2, 3],\n",
        "        'validation_fraction': [0.1, 0.2],\n",
        "        'n_iter_no_change': [5, 10],\n",
        "        'tol': [1e-4],\n",
        "    }\n",
        "]\n",
        "\n",
        "model = GradientBoostingRegressor(random_state=42)\n",
        "\n",
        "best_models = {}\n",
        "for column in y_train.columns:\n",
        "    grid_search = GridSearchCV(\n",
        "        estimator=model,\n",
        "        param_grid=param_grid,\n",
        "        scoring=custom_scorer_func,\n",
        "        cv=5,\n",
        "        n_jobs=-1,\n",
        "        verbose=2\n",
        "    )\n",
        "    grid_search.fit(X_train, y_train[column])\n",
        "    best_models[column] = grid_search.best_estimator_\n",
        "    print(f\"Лучшие параметры для {column}: {grid_search.best_params_}\")\n",
        "\n",
        "y_pred_test = pd.DataFrame()\n",
        "for column, model in best_models.items():\n",
        "    y_pred_test[column] = model.predict(X_test)\n",
        "\n",
        "percentage_error_test = get_smoothed_mean_log_accuracy_ratio(y_test, y_pred_test)\n",
        "print(f'Percentage Error on Test: {percentage_error_test}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgEQaWoTlVUH",
        "outputId": "55f9267f-8aec-43d9-ddee-00aeafd33e87"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 151 candidates, totalling 755 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лучшие параметры для at_least_one: {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 50}\n",
            "Fitting 5 folds for each of 151 candidates, totalling 755 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лучшие параметры для at_least_two: {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 50}\n",
            "Fitting 5 folds for each of 151 candidates, totalling 755 fits\n",
            "Лучшие параметры для at_least_three: {'learning_rate': 0.01, 'max_depth': 1, 'n_estimators': 50}\n",
            "Percentage Error on Test: 248.21%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan]\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Percentage Error on Test: {percentage_error_test}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcijujRZsng9",
        "outputId": "cbdc2847-8bdb-4743-c4e6-b927eb6b31c9"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percentage Error on Test: 248.21%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
        "custom_scorer_func = make_scorer(get_smoothed_mean_log_accuracy_ratio,\n",
        "                                greater_is_better=False)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "models = {\n",
        "        'Decision Tree': (DecisionTreeRegressor(), {\n",
        "            'max_depth': [1, 2, 3, 5, 7],\n",
        "            'min_samples_split': [2, 5, 10, 20],\n",
        "            'min_samples_leaf': [1, 2, 5, 10],\n",
        "            'max_features': ['sqrt', 'log2', None]\n",
        "        }),\n",
        "        'Random Forest': (RandomForestRegressor(), {\n",
        "            'n_estimators': [50, 100, 150, 200],\n",
        "            'max_depth': [3, 5],\n",
        "            'min_samples_split': [2, 5, 10],\n",
        "            #'min_samples_leaf': [1, 2, 4],\n",
        "            'max_features': ['sqrt', 'log2', 0.8, None],\n",
        "            'bootstrap': [True, False]\n",
        "        })\n",
        "}\n",
        "\n",
        "error_res = {}\n",
        "\n",
        "for model_name, (model, params) in models.items():\n",
        "    grid_search = GridSearchCV(\n",
        "        estimator=model,\n",
        "        param_grid=params,\n",
        "        scoring=custom_scorer_func,\n",
        "        cv=5,\n",
        "        n_jobs=-1,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "    best_model = grid_search.best_estimator_\n",
        "\n",
        "    y_pred_train = best_model.predict(X_train_scaled)\n",
        "    y_pred_test = best_model.predict(X_test_scaled)\n",
        "\n",
        "    responses_train = pd.DataFrame(y_pred_train, columns=['at_least_one', 'at_least_two', 'at_least_three'])\n",
        "    answers_train = pd.DataFrame(y_train.reset_index(drop=True), columns=['at_least_one', 'at_least_two', 'at_least_three'])\n",
        "\n",
        "    responses_test = pd.DataFrame(y_pred_test, columns=['at_least_one', 'at_least_two', 'at_least_three'])\n",
        "    answers_test = pd.DataFrame(y_test.reset_index(drop=True), columns=['at_least_one', 'at_least_two', 'at_least_three'])\n",
        "\n",
        "    train_error = get_smoothed_mean_log_accuracy_ratio(answers_train, responses_train)\n",
        "    test_error = get_smoothed_mean_log_accuracy_ratio(answers_test, responses_test)\n",
        "\n",
        "    error_res[model_name] = {\n",
        "        'best_params': grid_search.best_params_,\n",
        "        'train_error': train_error,\n",
        "        'test_error': test_error,\n",
        "        'model': best_model\n",
        "    }"
      ],
      "metadata": {
        "id": "ZmCNPXJZLWSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model_name, errors in error_res.items():\n",
        "    print(f\"\\n{model_name}:\")\n",
        "    print(f\"Best Parameters: {errors['best_params']}\")\n",
        "    print(f\"Train Error: {errors['train_error']:.2f}%\")\n",
        "    print(f\"Test Error: {errors['test_error']:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifhjAeyLMSQM",
        "outputId": "d99c62c2-60a0-431e-919a-10cbb7149538"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Decision Tree:\n",
            "Best Parameters: {'max_depth': 1, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
            "Train Error: 227.65%\n",
            "Test Error: 247.27%\n",
            "\n",
            "Random Forest:\n",
            "Best Parameters: {'bootstrap': True, 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 50}\n",
            "Train Error: 152.90%\n",
            "Test Error: 344.42%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "К сожалению я столкнулся с сильным переобучением и пока не понял как от него избавится."
      ],
      "metadata": {
        "id": "ndnx8G6NuQ6D"
      }
    }
  ]
}